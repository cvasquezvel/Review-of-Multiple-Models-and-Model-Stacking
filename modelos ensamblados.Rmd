---
title: "Revisión de muchos modelos y Ensamblado de modelos"
author: 
 - PhD(c). Christian Vásquez Velasco
date: "`r Sys.Date()`"
output: html_document
---

```{=html}
<style>
body {
text-align: justify}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(max.print = 9999,
        scipen = 999)
library(pacman)
pacman::p_load(tidymodels, rules, baguette, finetune, ggrepel, stacks, doParallel)
tidymodels_prefer()

### Parallel process ----

# speed up computation with parallel processing

doParallel::registerDoParallel()

ncores <- parallel::detectCores(logical = TRUE)
registerDoParallel(cores = ncores)
```

# Modelización de la resistencia de la mezcla de hormigón

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
data(concrete, package = "modeldata")
glimpse(concrete)
```

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
concrete <- 
   concrete %>% 
   group_by(across(-compressive_strength)) %>% 
   summarize(compressive_strength = mean(compressive_strength),
             .groups = "drop")
nrow(concrete)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
set.seed(1501)
concrete_split <- initial_split(concrete, strata = compressive_strength)
concrete_train <- training(concrete_split)
concrete_test  <- testing(concrete_split)

set.seed(1502)
concrete_folds <- 
   vfold_cv(concrete_train, strata = compressive_strength, repeats = 5)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
normalized_rec <- 
   recipe(compressive_strength ~ ., data = concrete_train) %>% 
   step_normalize(all_predictors()) 

poly_recipe <- 
   normalized_rec %>% 
   step_poly(all_predictors()) %>% 
   step_interact(~ all_predictors():all_predictors())
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
linear_reg_spec <- 
   linear_reg(penalty = tune(), mixture = tune()) %>% 
   set_engine("glmnet")

nnet_spec <- 
   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
   set_engine("nnet", MaxNWts = 2600) %>% 
   set_mode("regression")

mars_spec <- 
   mars(prod_degree = tune()) %>%  #<- use GCV to choose terms
   set_engine("earth") %>% 
   set_mode("regression")

svm_r_spec <- 
   svm_rbf(cost = tune(), rbf_sigma = tune()) %>% 
   set_engine("kernlab") %>% 
   set_mode("regression")

svm_p_spec <- 
   svm_poly(cost = tune(), degree = tune()) %>% 
   set_engine("kernlab") %>% 
   set_mode("regression")

knn_spec <- 
   nearest_neighbor(neighbors = tune(), dist_power = tune(), weight_func = tune()) %>% 
   set_engine("kknn") %>% 
   set_mode("regression")

cart_spec <- 
   decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
   set_engine("rpart") %>% 
   set_mode("regression")

bag_cart_spec <- 
   bag_tree() %>% 
   set_engine("rpart", times = 50L) %>% 
   set_mode("regression")

rf_spec <- 
   rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
   set_engine("ranger") %>% 
   set_mode("regression")

xgb_spec <- 
   boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
              min_n = tune(), sample_size = tune(), trees = tune()) %>% 
   set_engine("xgboost") %>% 
   set_mode("regression")

cubist_spec <- 
   cubist_rules(committees = tune(), neighbors = tune()) %>% 
   set_engine("Cubist")
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
nnet_param <- 
   nnet_spec %>% 
   extract_parameter_set_dials() %>% 
   update(hidden_units = hidden_units(c(1, 27)))
```

## Creación del conjunto de flujos de trabajo

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
normalized <- 
   workflow_set(
      preproc = list(normalized = normalized_rec), 
      models = list(SVM_radial = svm_r_spec, SVM_poly = svm_p_spec, 
                    KNN = knn_spec, neural_network = nnet_spec)
   )
normalized
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
normalized %>% extract_workflow(id = "normalized_KNN")
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
normalized <- 
   normalized %>% 
   option_add(param_info = nnet_param, id = "normalized_neural_network")
normalized
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
model_vars <- 
   workflow_variables(outcomes = compressive_strength, 
                      predictors = everything())

no_pre_proc <- 
   workflow_set(
      preproc = list(simple = model_vars), 
      models = list(MARS = mars_spec, CART = cart_spec, CART_bagged = bag_cart_spec,
                    RF = rf_spec, boosting = xgb_spec, Cubist = cubist_spec)
   )
no_pre_proc
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
with_features <- 
   workflow_set(
      preproc = list(full_quad = poly_recipe), 
      models = list(linear_reg = linear_reg_spec, KNN = knn_spec)
   )
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
all_workflows <- 
   bind_rows(no_pre_proc, normalized, with_features) %>% 
   # Make the workflow ID's a little more simple: 
   mutate(wflow_id = gsub("(simple_)|(normalized_)", "", wflow_id))
all_workflows
```

## Ajuste y evaluación de los modelos

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      parallel_over = "everything",
      save_workflow = TRUE
   )

grid_results <-
   all_workflows %>%
   workflow_map(
      seed = 1503,
      resamples = concrete_folds,
      grid = 25,
      control = grid_ctrl
   )
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
grid_ctrl <-
   control_grid(
      save_pred = TRUE,
      parallel_over = "everything",
      save_workflow = TRUE
   )

full_results_time <- 
   system.time(
      grid_results <- 
         all_workflows %>% 
         workflow_map(seed = 1503, resamples = concrete_folds, grid = 25, 
                      control = grid_ctrl, verbose = TRUE)
   )
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
grid_results
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
grid_results %>% 
   rank_results() %>% 
   filter(.metric == "rmse") %>% 
   select(model, .config, rmse = mean, rank)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(
   grid_results,
   rank_metric = "rmse",  # <- how to order models
   metric = "rmse",       # <- which metric to visualize
   select_best = TRUE     # <- one point per workflow
) +
   geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +
   lims(y = c(3.5, 9.5)) +
   theme(legend.position = "none")
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(grid_results, id = "Cubist", metric = "rmse")
```

## Selección eficaz de los modelos

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
race_ctrl <-
   control_race(
      save_pred = TRUE,
      parallel_over = "everything",
      save_workflow = TRUE
   )

race_results <-
   all_workflows %>%
   workflow_map(
      "tune_race_anova",
      seed = 1503,
      resamples = concrete_folds,
      grid = 25,
      control = race_ctrl
   )
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
race_results
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(
   race_results,
   rank_metric = "rmse",  
   metric = "rmse",       
   select_best = TRUE    
) +
   geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +
   lims(y = c(3.0, 9.5)) +
   theme(legend.position = "none")
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
matched_results <- 
   rank_results(race_results, select_best = TRUE) %>% 
   select(wflow_id, .metric, race = mean, config_race = .config) %>% 
   inner_join(
      rank_results(grid_results, select_best = TRUE) %>% 
         select(wflow_id, .metric, complete = mean, 
                config_complete = .config, model),
      by = c("wflow_id", ".metric"),
   ) %>%  
   filter(.metric == "rmse")

matched_results %>% 
   ggplot(aes(x = complete, y = race)) + 
   geom_abline(lty = 3) + 
   geom_point() + 
   geom_text_repel(aes(label = model)) +
   coord_obs_pred() + 
   labs(x = "Complete Grid RMSE", y = "Racing RMSE")
```

## Finalizar un modelo

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
best_results <- 
   race_results %>% 
   extract_workflow_set_result("boosting") %>% 
   select_best(metric = "rmse")
best_results

boosting_test_results <- 
   race_results %>% 
   extract_workflow("boosting") %>% 
   finalize_workflow(best_results) %>% 
   last_fit(split = concrete_split)
```

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
collect_metrics(boosting_test_results)
```

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
boosting_test_results %>% 
   collect_predictions() %>% 
   ggplot(aes(x = compressive_strength, y = .pred)) + 
   geom_abline(color = "gray50", lty = 2) + 
   geom_point(alpha = 0.5) + 
   coord_obs_pred() + 
   labs(x = "observed", y = "predicted")
```

## Creación del conjunto de entrenamiento para el apilamiento

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
concrete_stack <- 
  stacks() %>% 
  add_candidates(race_results)

concrete_stack
```

## Mezclar las predicciones
  
```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
set.seed(2001)
ens <- blend_predictions(concrete_stack)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(ens)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
set.seed(2002)
ens <- blend_predictions(concrete_stack, penalty = 10^seq(-2, -0.5, length = 20))
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(ens)
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
ens
```


```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
autoplot(ens, "weights") +
  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + 
  theme(legend.position = "none") +
  lims(x = c(-0.01, 0.8))
```

## Ajustar los modelos de los miembros

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
ens <- fit_members(ens)
```

## Resultados del conjunto de pruebas

```{r,echo=FALSE,comment=NA, warning=FALSE,message=FALSE}
reg_metrics <- metric_set(rmse, rsq)
ens_test_pred <- 
  predict(ens, concrete_test) %>% 
  bind_cols(concrete_test)

ens_test_pred %>% 
  reg_metrics(compressive_strength, .pred)
```